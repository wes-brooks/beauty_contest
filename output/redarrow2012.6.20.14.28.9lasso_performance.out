# fold = 1
# threshold = 2.47240631965
# requested specificity = 0.966666666667
# actual training-set specificity = 0.944444444444
# tpos = 6
# tneg = 0
# fpos = 10
# fneg = 0
# raw predictions:
[484.09096 396.41063 391.03944 89.17358 1006.4352 803.29596 764.80594
 153.8827 92.43857 737.12931 101.81213 128.70379 116.89679 77.503264
 54.812921 41.13257]
# truth:
[3.1138 1.6599 2.6888 3.3837 2.5367 2.2867 1.6464 2.2227 0.9345 1.5843
 1.9934 2.6638 3.3837 2.3398 2.236 2.3516]
# fold = 2
# threshold = 2.18573326256
# requested specificity = 0.814814814815
# actual training-set specificity = 0.8
# tpos = 2
# tneg = 4
# fpos = 4
# fneg = 5
# raw predictions:
[2.1324872 2.1399924 2.1527294 2.1928834 2.1945992 2.1917091 2.1938585
 2.1913584 2.0866405 2.0976362 2.1485074 2.1138 2.1063233 2.1338926
 2.1870461]
# truth:
[2.6888 1.933 3.3837 2.2695 3.0492 1.7952 3.3837 2.2363 1.8899 2.5628
 3.0804 0.7076 3.3837 1.1903 2.3041]
# fold = 3
# threshold = 2.48199569870
# requested specificity = 0.962962962963
# actual training-set specificity = 0.942857142857
# tpos = 2
# tneg = 5
# fpos = 5
# fneg = 3
# raw predictions:
[4.7259614 3.3698368 3.6731185 1.4360633 1.6096373 3.5962927 3.4475681
 4.0821418 3.2598626 2.4276836 2.0233406 2.3625153 1.6779881 2.0047701
 2.2159296]
# truth:
[3.298 2.3577 1.8651 1.1173 1.5441 1.4928 1.7308 1.6375 2.588 2.8615 1.9939
 1.7582 3.3837 1.8681 3.3837]
# fold = 4
# threshold = 2.33306343441
# requested specificity = 0.866666666667
# actual training-set specificity = 0.864864864865
# tpos = 4
# tneg = 6
# fpos = 3
# fneg = 2
# raw predictions:
[2.8144749 2.0282861 2.1168527 2.4867053 2.0965844 2.3737591 2.2571189
 2.0532988 1.9910948 2.6250055 1.8597553 2.4759682 2.5143257 2.0155722
 2.7133097]
# truth:
[1.3541 0.0 2.4366 2.6387 3.2388 2.588 2.0969 2.0195 2.1196 2.3308 1.2068
 2.2227 3.1138 2.2238 3.3837]
# fold = 5
# threshold = 2.31199350888
# requested specificity = 0.928571428571
# actual training-set specificity = 0.914285714286
# tpos = 1
# tneg = 11
# fpos = 1
# fneg = 1
# raw predictions:
[2.2532772 2.3522309 2.2418926 2.2397212 2.2901144 2.2571364 2.2795085
 2.2515398 2.3547598 2.278466 2.2665352 2.2370344 2.2691139 2.2557271]
# truth:
[1.0374 3.0492 1.3032 2.3829 2.2871 1.7024 2.1912 1.8848 2.1878 1.8681
 1.0374 1.3201 1.9504 2.1761]
# fold = overall performance
# tpos = 15
# tneg = 26
# fpos = 23
# fneg = 11
