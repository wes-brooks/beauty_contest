# fold = 1
# threshold = 0.28361949754
# requested specificity = 0.806451612903
# actual training-set specificity = 0.696202531646
# tpos = 2
# tneg = 14
# fpos = 4
# fneg = 1
# raw predictions:
[0.290392906631 0.273598905291 0.26594655407 0.255033528375 0.254906717559
 0.303187741183 0.24203493075 0.249838929709 0.276706958773 0.281099135458
 0.283820641986 0.250116119261 0.257380626136 0.277965182444 0.241021443067
 0.250602697169 0.291879535043 0.286224132297 0.283936076981 0.267492229624
 0.251776492532]
# truth:
[2.5366847 2.5779511 1.7767012 2.1664301 0.79934055 2.512551 1.382017
 1.5024271 1.3961993 1.8469553 1.6884198 1.3483049 2.2000293 2.1433271
 0.30103 1.0374265 1.1271048 1.5024271 1.6928469 1.5263393 0.0]
# fold = 2
# threshold = 0.236174035074
# requested specificity = 0.809523809524
# actual training-set specificity = 0.7125
# tpos = 3
# tneg = 10
# fpos = 4
# fneg = 3
# raw predictions:
[0.188950322708 0.274274421894 0.242203688807 0.193009842132 0.164127673141
 0.248778036808 0.256060926593 0.172759875828 0.280182780933 0.169060700612
 0.1984929119 0.164379810246 0.331054790931 0.22437623342 0.193220666822
 0.163567773426 0.167484507353 0.169450050515 0.164366122367 0.312318695516]
# truth:
[2.5375673 2.4350476 3.3837436 0.30103 1.376577 2.5627685 2.1580608
 2.1804126 1.1643529 1.6532125 2.2671717 1.7024305 2.0338257 3.3837436
 1.4593925 1.3710679 3.3837436 1.9355073 0.70757018 2.1525941]
# fold = 3
# threshold = 0.198377715423
# requested specificity = 0.809523809524
# actual training-set specificity = 0.7125
# tpos = 4
# tneg = 8
# fpos = 4
# fneg = 4
# raw predictions:
[0.198790979077 0.198280233682 0.198400657544 0.198779490795 0.198693344596
 0.198423601661 0.198294566971 0.198392054015 0.198283100278 0.198280233682
 0.198280233682 0.198280233682 0.198377715423 0.198420733537 0.198280233682
 0.198280233682 0.198383450766 0.198280233682 0.198280233682 0.198280233682]
# truth:
[3.3837436 1.1172713 1.8469553 3.3837436 1.5263393 2.2000293 2.8121108
 1.8709888 1.687529 1.1430148 1.3579348 2.2796669 2.4637437 2.7136585
 1.9020029 3.3837436 2.6190933 0.61278386 1.39794 2.5161386]
# fold = 4
# threshold = 0.254102383757
# requested specificity = 0.809523809524
# actual training-set specificity = 0.725
# tpos = 2
# tneg = 15
# fpos = 1
# fneg = 2
# raw predictions:
[0.254008252016 0.25409247407 0.253988437738 0.254003298351 0.25422131988
 0.253993391212 0.253983484328 0.253983484328 0.254028067313 0.254226276348
 0.254756986342 0.253983484328 0.253983484328 0.254023113393 0.254023113393
 0.253983484328 0.253983484328 0.253983484328 0.253983484328 0.253983484328]
# truth:
[2.286681 1.5717088 2.5880475 2.0297895 2.2367891 1.3384565 1.3031961
 1.6009729 2.0318123 2.9914033 2.7567882 2.2355284 1.4712917 2.3380579
 1.6866363 1.5786392 1.9703469 2.0406023 2.6887757 2.1195858]
# fold = 5
# threshold = 0.236679177678
# requested specificity = 0.8125
# actual training-set specificity = 0.716049382716
# tpos = 3
# tneg = 12
# fpos = 2
# fneg = 2
# raw predictions:
[0.338463283626 0.280250399087 0.191962861066 0.181313000982 0.274604340824
 0.205694652636 0.354299041511 0.206876185229 0.517595245057 0.193814485343
 0.212918148411 0.182604039772 0.19482289454 0.181850920196 0.192104335086
 0.204406925034 0.182133362949 0.200632398822 0.199504575956]
# truth:
[3.2980448 1.8920946 3.3837436 2.4834446 2.6134189 1.6042261 3.3837436
 2.3398488 2.0674428 2.3583156 2.1027766 2.1598678 1.8000294 0.30103
 1.948413 1.1643529 1.9355073 1.666518 0.49136169]
# fold = overall performance
# tpos = 14
# tneg = 59
# fpos = 15
# fneg = 12
