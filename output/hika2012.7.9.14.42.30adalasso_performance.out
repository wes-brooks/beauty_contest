# fold = 1
# threshold = 0.303775373774
# requested specificity = 0.806451612903
# actual training-set specificity = 0.818181818182
# tpos = 0
# tneg = 16
# fpos = 3
# fneg = 2
# raw predictions:
[0.303849788852 0.303868394227 0.303677719575 0.303677719575 0.303677719575
 0.303677719575 0.303677719575 0.303677719575 0.303682369374 0.303677719575
 0.303714919087 0.303677719575 0.303677719575 0.303677719575 0.303714919087
 0.303677719575 0.303677719575 0.303677719575 0.303677719575 0.303817230991
 0.303677719575]
# truth:
[0.30103 2.1580608 2.2000293 2.1664301 1.1430148 1.7024305 1.3031961
 1.6009729 2.4637437 3.3837436 1.6884198 1.3483049 2.2000293 0.61278386
 1.6866363 1.9703469 1.0374265 1.9355073 0.70757018 0.49136169 0.0]
# fold = 2
# threshold = 0.237599665632
# requested specificity = 0.809523809524
# actual training-set specificity = 0.819672131148
# tpos = 3
# tneg = 11
# fpos = 2
# fneg = 4
# raw predictions:
[0.237317303283 0.237509522023 0.237834381306 0.237878253781 0.237329945593
 0.23731129862 0.237440877582 0.237951664633 0.237776354401 0.237329929301
 0.237980189998 0.23731129862 0.23731129862 0.237311651593 0.237311488003
 0.237440332306 0.23738235734 0.237311621726 0.237366524304 0.23731129862]
# truth:
[3.2980448 3.3837436 2.0297895 3.3837436 1.5263393 2.1804126 1.3384565
 2.512551 3.3837436 2.0318123 2.0338257 1.8469553 1.3710679 1.9355073
 2.1433271 1.948413 2.6887757 2.5161386 1.666518 1.5263393]
# fold = 3
# threshold = 0.238452092961
# requested specificity = 0.809523809524
# actual training-set specificity = 0.819672131148
# tpos = 5
# tneg = 11
# fpos = 2
# fneg = 2
# raw predictions:
[0.344717655044 0.225844939414 0.257284779842 0.226628695542 0.225850324102
 0.248382514625 0.287347951057 0.228803271057 0.225844939414 0.225844939414
 0.226173571724 0.22587186376 0.225850324102 0.255999510756 0.405389790871
 0.225844939414 0.247748443964 0.225844939414 0.226006519584 0.225861093749]
# truth:
[3.3837436 1.7767012 2.4350476 2.5880475 1.376577 1.8920946 2.6134189
 2.8121108 0.79934055 1.382017 2.2671717 2.3398488 1.3961993 2.7136585
 2.0674428 2.1598678 2.6190933 0.30103 1.1271048 1.6928469]
# fold = 4
# threshold = 0.300026701511
# requested specificity = 0.809523809524
# actual training-set specificity = 0.821428571429
# tpos = 2
# tneg = 11
# fpos = 7
# fneg = 0
# raw predictions:
[0.300180330469 0.299944579991 0.300133188017 0.299945474033 0.300032580825
 0.299953019154 0.299939867031 0.29993544613 0.300034188204 0.299938488189
 0.30015650106 0.300175958781 0.299934076902 0.300119742956 0.300104685961
 0.30000234298 0.299939582891 0.29998020199 0.299988238377 0.30017810595]
# truth:
[2.286681 1.5717088 1.1643529 1.6532125 1.8709888 1.6042261 1.687529
 1.3579348 2.2796669 1.5024271 2.9914033 2.7567882 1.9020029 2.1027766
 2.3380579 1.39794 1.8000294 2.0406023 2.1195858 2.1525941]
# fold = 5
# threshold = 0.222207933483
# requested specificity = 0.8125
# actual training-set specificity = 0.825396825397
# tpos = 2
# tneg = 9
# fpos = 2
# fneg = 6
# raw predictions:
[0.222375990919 0.222375990919 0.222116304036 0.222101035087 0.222106124653
 0.222314868626 0.22218756905 0.222101035087 0.222345428273 0.222141753952
 0.222101035087 0.222101035087 0.222106124653 0.222106124653 0.222101035087
 0.222101035087 0.222101035087 0.222101035087 0.222116304036]
# truth:
[2.5366847 2.5375673 2.5779511 1.1172713 2.5627685 1.8469553 3.3837436
 2.4834446 2.2367891 1.4593925 2.2355284 3.3837436 3.3837436 2.3583156
 1.4712917 0.30103 1.5786392 1.1643529 1.5024271]
# fold = overall performance
# tpos = 12
# tneg = 58
# fpos = 16
# fneg = 14
