#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\begin_preamble
\renewcommand\[{\begin{equation}}
\renewcommand\]{\end{equation}}
\end_preamble
\use_default_options true
\begin_modules
theorems-ams
eqs-within-sections
figs-within-sections
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing double
\use_hyperref false
\papersize default
\use_geometry true
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine natbib_authoryear
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2cm
\topmargin 2cm
\bottommargin 2cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Beauty Contest
\end_layout

\begin_layout Abstract
Pithy, concise and informative.
 May bring the reader to tears due to the beauty of it.
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Section
Methods
\end_layout

\begin_layout Subsection
Data Sources
\end_layout

\begin_layout Standard

\emph on
Possibly move this to the end of the section
\end_layout

\begin_layout Standard
Which sites
\end_layout

\begin_layout Standard
Where are they
\end_layout

\begin_layout Standard
What specific sources sources of data (plug EnDDAT)
\end_layout

\begin_layout Standard
Will include a map and tables
\end_layout

\begin_layout Subsection
Listing of specific statistical techniques
\end_layout

\begin_layout Standard
pls - this is just like the PLS method in Virtual Beach
\end_layout

\begin_layout Standard
gbm - just like in Virtual Beach
\end_layout

\begin_layout Standard
gbmcv - this one differs from gbm in that it chooses the number of trees
 by cross-validation, instead of the so-called "out-of-bag" estimator used
 by plain gbm.
 A little better but a lot slower than gbm.
\end_layout

\begin_layout Standard
- And these methods do variable selection in addition to model fitting:
\end_layout

\begin_layout Standard
adapt - uses the adaptive lasso for selection and fitting
\end_layout

\begin_layout Standard
adapt-select - adaptive lasso for selection, then take those variables and
 fit a model using R's lm() function 
\end_layout

\begin_layout Standard
adalasso-weighted - logistic regression via adaptive lasso with observations
 weighted based on their distance from the threshold
\end_layout

\begin_layout Standard
adalasso-weighted-select - like the above method but after selecting variables,
 they're fit using R's glm() function.
 
\end_layout

\begin_layout Standard
adalasso-unweighted - like adalasso-weighted but without the observation
 weights adalasso-unweighted-select - like the above method but after selecting
 variables, they're fit using R's glm() function.
 
\end_layout

\begin_layout Standard
galm - genetic algorithm used for selecting variables in a linear regression
 model 
\end_layout

\begin_layout Standard
galogistic-weighted - genetic algorithm used for selecting variables in
 a logistic regression model where observations are weighted based on their
 distance from the threshold galogistic-unweighted - just as above but without
 the observation weights.
 
\end_layout

\begin_layout Standard
spls - the sparse pls routine from the spls package 
\end_layout

\begin_layout Standard
spls-select - use sparse pls to select variables for linear regression,
 then fit the model using the lm() function.
\end_layout

\begin_layout Subsubsection
PLS
\end_layout

\begin_layout Subsubsection
GBM
\end_layout

\begin_layout Paragraph
GBM
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand citet
key "Friedman-2001"

\end_inset


\end_layout

\begin_layout Paragraph
GBM-CV
\end_layout

\begin_layout Subsubsection
SPLS
\end_layout

\begin_layout Standard
Sparse PLS (SPLS) is introduced in 
\begin_inset CommandInset citation
LatexCommand citet
key "Chun-Keles-2007"

\end_inset

 as a method for analyzing high-dimensional data.
\end_layout

\begin_layout Paragraph
SPLS
\end_layout

\begin_layout Paragraph
SPLS-select
\end_layout

\begin_layout Subsubsection
Adaptive Lasso
\end_layout

\begin_layout Standard
The adaptive lasso 
\begin_inset CommandInset citation
LatexCommand citet
key "Zou-2006"

\end_inset

 is a regression method that simultaneously selects relevant predictors
 and estimates their coefficients by adding an 
\begin_inset Formula $\ell_{1}$
\end_inset

 penalty to the negative log-likelihood.
 For linear regression, the adaptive lasso estiamtes 
\begin_inset Formula $\bm{{\beta}}$
\end_inset

 to minimize the criterion 
\begin_inset Formula $\sum_{i=1}^{n}(y_{i}-X_{i}\beta)^{2}+\lambda\sum_{j=1}^{p}\frac{{|\beta_{j}|}}{\tilde{{|\beta_{j}|^{\gamma}}}}$
\end_inset

, where 
\begin_inset Formula $\lambda$
\end_inset

 is a tuning parameter and 
\begin_inset Formula $\tilde{{\bm{{\beta}}}}$
\end_inset

 is the vector of the usual least squares coefficients.
\end_layout

\begin_layout Standard
In this work, 
\begin_inset Formula $\gamma$
\end_inset

 is set to one and the adaptive lasso tuning parameter 
\begin_inset Formula $\lambda$
\end_inset

 is selected to minimize the bias-corrected AIC of 
\begin_inset CommandInset citation
LatexCommand citet
key "Hurvich-Simonoff-Tsai-1998"

\end_inset

.
\end_layout

\begin_layout Paragraph
Gaussian
\end_layout

\begin_layout Subparagraph
adapt
\end_layout

\begin_layout Standard
Uses the adaptive lasso of 
\begin_inset CommandInset citation
LatexCommand citet
key "Zou-2006"

\end_inset

 to select variables and estimate their coefficients.
 
\end_layout

\begin_layout Subparagraph
adapt-select
\end_layout

\begin_layout Standard
Uses the adaptive lasso of 
\begin_inset CommandInset citation
LatexCommand citet
key "Zou-2006"

\end_inset

 to select variables, with the corrected AIC for selection of the tuning
 parameter.
 The results of the variable selection are used in a multiple linear regression
 model.
\end_layout

\begin_layout Paragraph
Logistic
\end_layout

\begin_layout Subparagraph
weighted
\end_layout

\begin_layout Subparagraph
weighted-select
\end_layout

\begin_layout Subparagraph
Unweighted
\end_layout

\begin_layout Subparagraph
Unweighted-select
\end_layout

\begin_layout Subsubsection
Genetic algorithm
\end_layout

\begin_layout Standard
The genetic algorithm 
\begin_inset CommandInset citation
LatexCommand citep
key "Fogel-1998"

\end_inset

 is a variable-selection method that works by analogy to natural selection,
 where so-called chromosomes represent regression models.
 Each chrom.
 A variable is included in the model if the corresponding element of the
 chrmosome is one, but not otherwise.
 Chromosomes are produced in successive generations, where the first generation
 is produced randomly and subsequent generations are produced by combining
 chromosomes from the current generation, with additional random drift.
 The chance that a chromosome in the current generation will produce offspring
 in the next generation is a determined by its fitness.
 The fitness of each chromosome is calculated by the corrected Akaike Informatio
n Criterion (AICc) 
\begin_inset CommandInset citation
LatexCommand citet
key "Akaike-1973,Hurvich-Tsai-1989"

\end_inset

.
\end_layout

\begin_layout Standard
Our implementation used 100 generations and each generation contained 200
 chromosomes.
 
\end_layout

\begin_layout Paragraph*
gaussian
\end_layout

\begin_layout Standard
placehold
\end_layout

\begin_layout Paragraph
logistic
\end_layout

\begin_layout Subparagraph
ga-unweighted
\end_layout

\begin_layout Subparagraph
ga-weighted
\end_layout

\begin_layout Subsection
Implementation for beach regression
\end_layout

\begin_layout Standard
Include a table with pre/post processing discussion
\end_layout

\begin_layout Standard
This includes tuning of parameters
\end_layout

\begin_layout Standard
Some specific data issues because we are estimating a threshold exceedence
\end_layout

\begin_layout Subsection
Cross Validation
\end_layout

\begin_layout Standard
Repeated 5-fold validation (similar to field conditions of having a few
 years)
\end_layout

\begin_layout Standard
Compare to fitting to half seasons? 
\emph on
probably not but maybe because low cost
\end_layout

\begin_layout Standard
More likely full seasons
\end_layout

\begin_layout Standard
Possibly leave-one-out ===> perhaps instead of 5-fold because more efficient
\end_layout

\begin_layout Standard

\series bold
Seasons + leave one out.
 
\series default
\emph on
Reserve 5-fold as a possibility if we need it.
\end_layout

\begin_layout Subsection
Performance Metrics
\end_layout

\begin_layout Standard
How did we evaluate the performance of each technique on all the different
 data sets
\end_layout

\begin_layout Itemize
for all cases ---> AUC (ROC curve)
\end_layout

\begin_layout Itemize
continuous variables using PRESS (skill --> Like Nash-Sutcliffe/R^2 over
 the fitted data) 
\end_layout

\begin_layout Itemize
True/False Positives/Negatives (needs a threshold)
\end_layout

\begin_layout Itemize
Which variables are selected for models where variable reduction takes place
\end_layout

\begin_deeper
\begin_layout Itemize
challenge regarding the fact that different variables are selected in each
 fold.
 Maybe use frequencies?
\end_layout

\begin_layout Itemize
also the number of variables selected (metric of complexity)
\end_layout

\end_deeper
\begin_layout Paragraph*
OPTIONAL
\end_layout

\begin_layout Itemize
AIC/BIC? --> not the same model in each fold so maybe not possible
\end_layout

\begin_layout Itemize
Maybe some form of confusion matrices -- perhaps a grid of them with or
 without companion variance plots or other estimates of the range of results
\end_layout

\begin_layout Section
Results
\end_layout

\begin_layout Itemize
Performance over prediction from cross validation
\end_layout

\begin_layout Itemize
Maybe anecdotal showing fit over data set
\end_layout

\begin_layout Section
Discussion
\end_layout

\begin_layout Standard
Which type of model is generally the best?
\end_layout

\begin_layout Standard
Under what conditions do some outperform others?
\end_layout

\begin_layout Section
Acknowledgments
\end_layout

\begin_layout Section
References
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "/home/wesley/git/beauty_contest/references/beautycontest"
options "plainnat"

\end_inset


\end_layout

\end_body
\end_document
